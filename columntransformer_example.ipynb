{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Jupyter Notebook contains the full code needed to write the ColumnTransformer blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and some pre-transformation data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csvs with waits and weather\n",
    "df = pd.read_csv('./data/dec2019.csv')\n",
    "weather_df = pd.read_csv('./data/dec2019weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "df.columns = ['date_hour', 'wait_hrs']\n",
    "\n",
    "# cut the date_hours to the hour (no minutes/seconds) and convert to string for merging\n",
    "df['date_hour'] = pd.to_datetime(df['date_hour'], utc=True).values.astype('datetime64[h]')\n",
    "df['date_hour'] = df['date_hour'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of all possible departure hours in the month (as string for merging)\n",
    "# note that I chose to include non-ferry service hours at this stage\n",
    "dts = pd.DataFrame(columns=['date_hour'])\n",
    "dts['date_hour'] = pd.date_range(start='2019-12-01 00:00', \n",
    "                    end='2019-12-31 23:30', \n",
    "                    freq='H',\n",
    "                   ).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge/join the waits to the dataframe of all departures\n",
    "df_expanded = dts.merge(df, how='left', on='date_hour')\n",
    "\n",
    "# cast as datetime with timezone UTC\n",
    "df_expanded['date_hour'] = pd.to_datetime(df_expanded['date_hour'], utc=True)\n",
    "\n",
    "# adjust time to PST\n",
    "df_expanded['date_hour'] = [dt.astimezone(timezone('US/Pacific')) for dt in df_expanded['date_hour']]\n",
    "\n",
    "# remove non-sailing times (1 to 4 am for Edmonds (1-3 for Kingston))\n",
    "df_expanded = df_expanded.set_index('date_hour')\n",
    "df_expanded = df_expanded.between_time('5:00', '00:59')\n",
    "\n",
    "# reset index for modeling\n",
    "df_expanded = df_expanded.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.columns = ['date', 'max_temp', 'avg_temp', 'min_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['date'] = pd.to_datetime(weather_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_hour</th>\n",
       "      <th>wait_hrs</th>\n",
       "      <th>date</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-30 16:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 17:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-30 18:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-30 19:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-30 20:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_hour  wait_hrs       date  max_temp  avg_temp  min_temp\n",
       "0 2019-11-30 16:00:00-08:00       NaN 2019-12-01        45      42.7        39\n",
       "1 2019-11-30 17:00:00-08:00       NaN 2019-12-01        45      42.7        39\n",
       "2 2019-11-30 18:00:00-08:00       NaN 2019-12-01        45      42.7        39\n",
       "3 2019-11-30 19:00:00-08:00       NaN 2019-12-01        45      42.7        39\n",
       "4 2019-11-30 20:00:00-08:00       NaN 2019-12-01        45      42.7        39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded['date'] = pd.to_datetime(df_expanded['date_hour']).values.astype('datetime64[D]')\n",
    "df_expanded = df_expanded.merge(weather_df, how='left', on='date')\n",
    "df_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Column Transformer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little cheating to extract the day of the week \n",
    "# and hour of the day w/out using a transformer \n",
    "# (see below for the \"real\" version)\n",
    "df_simple = df_expanded.copy()\n",
    "df_simple['weekday'] = [dt.weekday() for dt in df_simple['date_hour']]\n",
    "df_simple['hour'] = [dt.hour for dt in df_simple['date_hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_hour</th>\n",
       "      <th>wait_hrs</th>\n",
       "      <th>date</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-30 16:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 17:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-30 18:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-30 19:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-30 20:00:00-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_hour  wait_hrs       date  max_temp  avg_temp  \\\n",
       "0 2019-11-30 16:00:00-08:00       NaN 2019-12-01        45      42.7   \n",
       "1 2019-11-30 17:00:00-08:00       NaN 2019-12-01        45      42.7   \n",
       "2 2019-11-30 18:00:00-08:00       NaN 2019-12-01        45      42.7   \n",
       "3 2019-11-30 19:00:00-08:00       NaN 2019-12-01        45      42.7   \n",
       "4 2019-11-30 20:00:00-08:00       NaN 2019-12-01        45      42.7   \n",
       "\n",
       "   min_temp  weekday  hour  \n",
       "0        39        5    16  \n",
       "1        39        5    17  \n",
       "2        39        5    18  \n",
       "3        39        5    19  \n",
       "4        39        5    20  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_simple.drop(columns='wait_hrs')\n",
    "y = df_simple['wait_hrs'].fillna(value=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column transformer and set n_jobs to have it run on all cores\n",
    "col_transformer = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('ss', StandardScaler(), ['max_temp', 'avg_temp', 'min_temp']),\n",
    "                        ('ohe', OneHotEncoder(), ['weekday', 'hour'])],\n",
    "                    remainder='drop',\n",
    "                    n_jobs=-1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = col_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<465x30 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2325 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "            (\"preprocessing\", col_transformer),\n",
    "            (\"lr\", lr)\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=-1, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ss',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  ['max_temp', 'avg_temp',\n",
       "                                                   'min_temp']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['weekday', 'hour'])],\n",
       "                                   verbose=False)),\n",
       "                ('lr',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = pipe.predict(X_train)\n",
    "preds_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03650713, -0.17621553, -0.17410003,  0.43019621, -0.03297714])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34257865,  0.26820199,  0.230672  ,  0.13353943, -0.05221186])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ColumnTransformer.get_feature_names of ColumnTransformer(n_jobs=-1, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('ss',\n",
       "                                 StandardScaler(copy=True, with_mean=True,\n",
       "                                                with_std=True),\n",
       "                                 ['max_temp', 'avg_temp', 'min_temp']),\n",
       "                                ('ohe',\n",
       "                                 OneHotEncoder(categorical_features=None,\n",
       "                                               categories=None, drop=None,\n",
       "                                               dtype=<class 'numpy.float64'>,\n",
       "                                               handle_unknown='error',\n",
       "                                               n_values=None, sparse=True),\n",
       "                                 ['weekday', 'hour'])],\n",
       "                  verbose=False)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_transformer.get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_0.0', 'x0_1.0', 'x0_2.0', 'x0_3.0', 'x0_4.0', 'x0_5.0',\n",
       "       'x0_6.0', 'x1_0.0', 'x1_5.0', 'x1_6.0', 'x1_7.0', 'x1_8.0',\n",
       "       'x1_9.0', 'x1_10.0', 'x1_11.0', 'x1_12.0', 'x1_13.0', 'x1_14.0',\n",
       "       'x1_15.0', 'x1_16.0', 'x1_17.0', 'x1_18.0', 'x1_19.0', 'x1_20.0',\n",
       "       'x1_21.0', 'x1_22.0', 'x1_23.0'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_transformer.named_transformers_['ohe'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS col\n",
      "['x0_0.0' 'x0_1.0' 'x0_2.0' 'x0_3.0' 'x0_4.0' 'x0_5.0' 'x0_6.0' 'x1_0.0'\n",
      " 'x1_5.0' 'x1_6.0' 'x1_7.0' 'x1_8.0' 'x1_9.0' 'x1_10.0' 'x1_11.0'\n",
      " 'x1_12.0' 'x1_13.0' 'x1_14.0' 'x1_15.0' 'x1_16.0' 'x1_17.0' 'x1_18.0'\n",
      " 'x1_19.0' 'x1_20.0' 'x1_21.0' 'x1_22.0' 'x1_23.0']\n",
      "SS col\n"
     ]
    }
   ],
   "source": [
    "for transformer in col_transformer.named_transformers_.values():\n",
    "    try:\n",
    "        transformer.get_feature_names()\n",
    "    except:\n",
    "        print('SS col')\n",
    "    else:\n",
    "        print(transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex column transformer example: imputing THEN standard scale/ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define transformers\n",
    "si_0 = SimpleImputer(strategy='constant', fill_value=0)\n",
    "ss = StandardScaler()\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# define column groups with same processing\n",
    "cat_vars = ['weekday', 'hour']\n",
    "num_vars = ['max_temp', 'avg_temp', 'min_temp']\n",
    "\n",
    "# set up pipelines for each column group\n",
    "categorical_pipe = Pipeline([\n",
    "                        ('si_0', si_0), \n",
    "                        ('ohe', ohe)\n",
    "                    ])\n",
    "numeric_pipe = Pipeline([\n",
    "                    ('si_0', si_0), \n",
    "                    ('ss', ss)\n",
    "                    ])\n",
    "\n",
    "# set up columnTransformer\n",
    "col_transformer = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('nums', numeric_pipe, num_vars),\n",
    "                        ('cats', categorical_pipe, cat_vars)\n",
    "                    ],\n",
    "                    remainder='drop',\n",
    "                    n_jobs=-1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "            (\"preprocessing\", col_transformer),\n",
    "            (\"lr\", lr)\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=-1, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('nums',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('si_0',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=0,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  wi...\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categorical_features=None,\n",
       "                                                                                 categories=None,\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['weekday', 'hour'])],\n",
       "                                   verbose=False)),\n",
       "                ('lr',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = pipe.predict(X_train)\n",
    "preds_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03650713, -0.17621553, -0.17410003,  0.43019621, -0.03297714,\n",
       "        0.02531061,  0.49059563,  0.1217838 , -0.01996503,  0.00551134])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34257865,  0.26820199,  0.230672  ,  0.13353943, -0.05221186,\n",
       "        0.31987361,  0.46759719,  0.26077382,  0.09713265,  0.33097677])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_0.0', 'x0_1.0', 'x0_2.0', 'x0_3.0', 'x0_4.0', 'x0_5.0',\n",
       "       'x0_6.0', 'x1_0.0', 'x1_5.0', 'x1_6.0', 'x1_7.0', 'x1_8.0',\n",
       "       'x1_9.0', 'x1_10.0', 'x1_11.0', 'x1_12.0', 'x1_13.0', 'x1_14.0',\n",
       "       'x1_15.0', 'x1_16.0', 'x1_17.0', 'x1_18.0', 'x1_19.0', 'x1_20.0',\n",
       "       'x1_21.0', 'x1_22.0', 'x1_23.0'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_transformer.named_transformers_['cats'].named_steps['ohe'].get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class DateTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Extracts features from datetime column\n",
    "    \n",
    "    Returns:\n",
    "      hour: hour\n",
    "      day: Between 1 and the number of days in the given month of the given year.\n",
    "      month: Between 1 and 12 inclusive.\n",
    "      year: four-digit year\n",
    "      weekday:day of the week as an integer, where Monday is 0 and Sunday is 6\n",
    "   \"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        result = pd.DataFrame(x, columns=['date_hour'])\n",
    "        result['hour'] = [dt.hour for dt in result['date_hour']]\n",
    "        result['day'] = [dt.day for dt in result['date_hour']]\n",
    "        result['month'] = [dt.month for dt in result['date_hour']]\n",
    "        result['year'] = [dt.year for dt in result['date_hour']]\n",
    "        result['weekday'] = [dt.weekday() for dt in result['date_hour']]\n",
    "        return result[['hour', 'day', 'month', 'year', 'weekday']]\n",
    "    \n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return ['hour','day', 'month', 'year', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_expanded.drop(columns='wait_hrs')\n",
    "y = df_simple['wait_hrs'].fillna(value=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-30 16:00:00-08:00</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 17:00:00-08:00</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-30 18:00:00-08:00</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-30 19:00:00-08:00</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-30 20:00:00-08:00</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>45</td>\n",
       "      <td>42.7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_hour       date  max_temp  avg_temp  min_temp\n",
       "0 2019-11-30 16:00:00-08:00 2019-12-01        45      42.7        39\n",
       "1 2019-11-30 17:00:00-08:00 2019-12-01        45      42.7        39\n",
       "2 2019-11-30 18:00:00-08:00 2019-12-01        45      42.7        39\n",
       "3 2019-11-30 19:00:00-08:00 2019-12-01        45      42.7        39\n",
       "4 2019-11-30 20:00:00-08:00 2019-12-01        45      42.7        39"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_preprocessing = Pipeline([\n",
    "                            ('date', DateTransformer()),\n",
    "                            ('ohe', OneHotEncoder(categories='auto'))\n",
    "                        ])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('ss', StandardScaler(), ['max_temp', 'avg_temp', 'min_temp']),\n",
    "                        ('date_exp', time_preprocessing, ['date_hour'])],\n",
    "                    remainder='drop',\n",
    "                    )\n",
    "\n",
    "pipe = Pipeline([('preprocessor', ct),\n",
    "                 ('lr', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ss',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  ['max_temp', 'avg_temp',\n",
       "                                                   'min_temp']),\n",
       "                                                 ('date_exp',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('date',\n",
       "                                                                   DateTransformer()),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categorical_features=None,\n",
       "                                                                                 categories='auto',\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['date_hour'])],\n",
       "                                   verbose=False)),\n",
       "                ('lr',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = pipe.predict(X_train)\n",
    "preds_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.82076705e-02,  2.62009695e-02, -5.21708067e-02, -6.52233237e-02,\n",
       "       -1.11211785e-01, -9.46140689e-02, -9.04810834e-02, -1.11230439e-01,\n",
       "       -9.62220441e-02, -7.99745376e-02, -7.21982462e-02,  1.62152613e-01,\n",
       "        1.20068920e-01,  1.21630847e-01,  3.53592239e-01,  2.88009948e-01,\n",
       "        1.63729282e-01, -4.27206526e-02, -8.15189424e-02, -7.12604340e-02,\n",
       "       -1.00026123e-01, -9.98540705e-02, -9.26480995e-02, -7.06554219e-02,\n",
       "       -3.81379900e-02, -6.29363481e-02,  7.59606596e-03, -4.60395030e-02,\n",
       "       -2.92341090e-02,  6.01875823e-03,  2.37595657e-02, -1.55318118e-01,\n",
       "       -1.44277277e-01, -1.31853503e-03, -1.31386259e-01, -1.06119083e-02,\n",
       "       -9.77607993e-02, -7.09326755e-02, -1.41606296e-01, -1.89719433e-01,\n",
       "       -6.25971437e-02,  1.19002353e-01,  5.29794446e-02, -1.59556621e-02,\n",
       "       -5.71940050e-02,  2.93585503e-01,  1.72053864e-01,  7.57916892e-03,\n",
       "        1.37067836e-01,  6.40806520e-02,  1.33687587e-01,  6.27911284e-02,\n",
       "       -1.86649232e-02,  2.64144480e-01, -5.07436367e-02,  5.07436367e-02,\n",
       "       -1.67891290e-14, -9.39818772e-03,  3.92652867e-02, -4.87404438e-02,\n",
       "        7.86444268e-02,  7.72140793e-02, -2.47537529e-02, -1.12231408e-01])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_0', 'x0_5', 'x0_6', 'x0_7', 'x0_8', 'x0_9', 'x0_10', 'x0_11',\n",
       "       'x0_12', 'x0_13', 'x0_14', 'x0_15', 'x0_16', 'x0_17', 'x0_18',\n",
       "       'x0_19', 'x0_20', 'x0_21', 'x0_22', 'x0_23', 'x1_1', 'x1_2',\n",
       "       'x1_3', 'x1_4', 'x1_5', 'x1_6', 'x1_7', 'x1_8', 'x1_9', 'x1_10',\n",
       "       'x1_11', 'x1_12', 'x1_13', 'x1_14', 'x1_15', 'x1_16', 'x1_17',\n",
       "       'x1_18', 'x1_19', 'x1_20', 'x1_21', 'x1_22', 'x1_23', 'x1_24',\n",
       "       'x1_25', 'x1_26', 'x1_27', 'x1_28', 'x1_29', 'x1_30', 'x1_31',\n",
       "       'x2_11', 'x2_12', 'x3_2019', 'x4_0', 'x4_1', 'x4_2', 'x4_3',\n",
       "       'x4_4', 'x4_5', 'x4_6'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.named_transformers_['date_exp'].named_steps['ohe'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hour', 'day', 'month', 'year', 'weekday']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.named_transformers_['date_exp'].named_steps['date'].get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rare features with ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['cat1'] = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "df['cat2'] = [0, 0, 0, 0, 0, 2, 2, 2, 2, 2]\n",
    "df['num1'] = [np.nan, 1, 1.1, .9, .8, np.nan, 2, 2.2, 1.5, np.nan]\n",
    "df['num2'] = [1.1, 1.1, 1.1, 1.1, 1.1, 1.2, 1.2, 1.2, 1.2, 1.2]\n",
    "\n",
    "target = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([\n",
    "                ('si', SimpleImputer(add_indicator=True)),\n",
    "                ('ss', StandardScaler())\n",
    "            ])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "            transformers=[('ohe', OneHotEncoder(categories=[[0,1], [0,2]]), ['cat1', 'cat2']),\n",
    "                          ('numeric', num_pipe, ['num1', 'num2'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "            ('preprocessor', ct),\n",
    "            ('lr', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=[[0,\n",
       "                                                                             1],\n",
       "                                                                            [0,\n",
       "                                                                             2]],\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['cat1', 'cat2']),\n",
       "                                                 ('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('si',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['num1', 'num2'])],\n",
       "                                   verbose=False)),\n",
       "                ('lr',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00, -3.04388929e-01, -8.66025404e-01,\n",
       "        -4.08248290e-01],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00, -5.65293726e-01, -8.66025404e-01,\n",
       "        -4.08248290e-01],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00, -8.26198522e-01, -8.66025404e-01,\n",
       "        -4.08248290e-01],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  2.04375424e+00,  1.15470054e+00,\n",
       "        -4.08248290e-01],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  7.39230257e-01,  1.15470054e+00,\n",
       "        -4.08248290e-01],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00, -5.79325024e-16,  1.15470054e+00,\n",
       "         2.44948974e+00],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00, -1.08710332e+00, -8.66025404e-01,\n",
       "        -4.08248290e-01]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.70710678, -1.41421356],\n",
       "       [ 1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        -1.41421356,  0.70710678],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
